#数据迁移
    1、将老数据导入到数据库
    2、在数据库加入file_key字段
      ALTER TABLE `reader`.`article_source` ADD COLUMN `file_key` VARCHAR(256) NULL;
      ALTER TABLE `reader`.`article` ADD COLUMN `file_key` VARCHAR(256) NULL;
    3、执行升级程序，将文章导入
    4、充命名表：
    ALTER TABLE `reader`.`article_source` RENAME TO  `reader`.`article_source_old` ;
    ALTER TABLE `reader`.`article` RENAME TO  `reader`.`article_old` ;
    
    5、新建结构表，将数据导入
	CREATE TABLE  article (
	  `id` bigint(20) NOT NULL AUTO_INCREMENT,
	  `feed_id` bigint(20) DEFAULT NULL,
	  `title` varchar(128) DEFAULT NULL,
	  `short_desc` varchar(64) DEFAULT NULL,
	  `author` varchar(32) DEFAULT NULL,
	  `publish_date` datetime DEFAULT NULL,
	  `status` tinyint(4) DEFAULT NULL,
	  `sort` int(11) DEFAULT NULL,
	  `url` varchar(1024) DEFAULT NULL,
	  `file_key` varchar(256) DEFAULT NULL,
	  `gmt_modified` datetime DEFAULT NULL,
	  `gmt_create` datetime DEFAULT NULL,
	  PRIMARY KEY (`id`),
	  KEY `feed_id_query` (`feed_id`,`status`),
	  KEY `query_home` (`status`,`publish_date`,`sort`),
	  KEY `title_query` (`title`,`status`)
	) ENGINE=MYISAM AUTO_INCREMENT= 1 DEFAULT CHARSET=utf8;
	
	CREATE TABLE `article_source` (
	   `id` bigint(20) NOT NULL AUTO_INCREMENT,
	   `feed_id` bigint(20) DEFAULT NULL,
	   `title` varchar(128) DEFAULT NULL,
	   `short_desc` varchar(64) DEFAULT NULL,
	   `author` varchar(32) DEFAULT NULL,
	   `status` tinyint(4) DEFAULT NULL,
	   `sort` int(11) DEFAULT NULL,
	   `url` varchar(1024) DEFAULT NULL,
	   `file_key` varchar(256) DEFAULT NULL,
	   `gmt_modified` datetime DEFAULT NULL,
	   `gmt_create` datetime DEFAULT NULL,
	 PRIMARY KEY (`id`)
	) ENGINE=MYISAM AUTO_INCREMENT=0 DEFAULT CHARSET=utf8;

	
	insert into reader.article(id, feed_id, title, short_desc, author, publish_date, status, sort, url, file_key, gmt_modified, gmt_create) 
	   select o.id, o.feed_id, o.title, o.short_desc, o.author, o.publish_date, o.status, o.sort, o.url, o.file_key, o.gmt_modified, o.gmt_create from reader.article_old o where o.id > 0;
	
	  insert into reader.article_source(id, feed_id, title, short_desc, author,  status, sort, url, file_key, gmt_modified, gmt_create) 
	   select o.id, o.feed_id, o.title, o.short_desc, o.author,  o.status, o.sort, o.url, o.file_key, o.gmt_modified, o.gmt_create from reader.article_source_old o where o.id > 0;


    6、导出数据，将数据传到阿里云服务器并导入
    msyqldump -uroot -p reader > reader.sql
    scp -i ~/.ssh/aliyun_rsa  reader.sql root@115.29.186.140:~/reader.sql;
    tar -zcvf  2013.tar.gz  2013 
    scp -i ~/.ssh/aliyun_rsa  2013.tar.gz root@115.29.186.140:~/2013.tar.gz;
    tar -zxvf 2013.tar.gz
    mv 2013   /var/data/store/
    mysql -u root -p reader < reader.sql
    
    7、验证数据正确，清理数据
    
    http://www.curiousmentality.co.uk/2011/11/tuning-jvm-memory-settings/
    
    
    
## TAR
	Tar是在Linux中使用得非常广泛的文档打包格式。它的好处就是它只消耗非常少的CPU以及时间去打包文件，他仅仅只是一个打包工具，并不负责压缩。下面是如何打包一个目录：
	# tar -cvf archive_name.tar directory_to_compress
	如何解包：
	# tar -xvf archive_name.tar.gz
	上面这个解包命令将会将文档解开在当前目录下面。当然，你也可以用这个命令来捏住解包的路径：
	# tar -xvf archive_name.tar -C /tmp/extract_here/
	TAR.GZ
	这种格式是我使用得最多的压缩格式。它在压缩时不会占用太多CPU的，而且可以得到一个非常理想的压缩率。使用下面这种格式去压缩一个目录：
	# tar -zcvf archive_name.tar.gz directory_to_compress
	解压缩：
	# tar -zxvf archive_name.tar.gz
	上面这个解包命令将会将文档解开在当前目录下面。当然，你也可以用这个命令来捏住解包的路径：
	# tar -zxvf archive_name.tar.gz -C /tmp/extract_here/
	TAR.BZ2
	这种压缩格式是我们提到的所有方式中压缩率最好的。当然，这也就意味着，它比前面的方式要占用更多的CPU与时间。这个就是你如何使用tar.bz2进行压缩。
	# tar -jcvf archive_name.tar.bz2 directory_to_compress
	上面这个解包命令将会将文档解开在当前目录下面。当然，你也可以用这个命令来捏住解包的路径：
	# tar -jxvf archive_name.tar.bz2 -C /tmp/extract_here/
	数据压缩是非常有用的，尤其是对于备份来说。所以，你现在应该考虑在你的备份脚本中使用你在这里学到的压缩方式备份你基本的规则文件以减小你备份文件的大小。
	过段时间之后，你就会意识到，在压缩率与CPU占用时间上会有一个平衡，你也要学会如何去权衡什么时候你需要一个快但是压缩率低，什么时候需要一个压缩率高但是CPU点用高的压缩方式，然后你才能避免无谓的空间与时间。
	来源：http://www.simplehelp.net/2008/12/15/how-to-create-and-extract-zip-tar-targz-and-tarbz2-files-in-linux/
       
##  sql导入导出数据方法
	Posted by lingxi on 2012 年 2 月 10 日 Leave a commentGo to comments
	摘要：在平时的mysql应用中，总会碰到导入数据，导出数据，当然有很多方法，这篇文章，主要介绍应用mysqlmysqldump命令进行数据导入导出，希望对大家有所帮助。
	
	
	
	一、mysql导入文件或数据或执行相关SQL
	
	mysql -h主机地址 -u用户名 -p用户密码
	
	1. 文件形式。(shell命令行）
	
	1
	mysql -u root -p dbname < filename.sql
	2. 直接放在命令行（shell命令行）执行一个sql
	
	1
	mysql -hhostname -uusername -p dbname -e 'select * from tbname limit 1'
	执行后命令行会提示输入数据库密码。:)
	
	3. 把SQL作为一个输入给MYSQL（shell命令行）
	
	1
	echo 'select id from dbname.tbname where id = 1;' | mysql -hhostname -ureadonly -preadonly dbname > xxxx.sql
	４.　进入mysql数据库（数据库中执行SQL文件）
	
	1
	>source xxx.sql
	二、导出库表（mysqldump）
	
	mysqldump -u用户名 -p密码 -h主机 数据库 a -w “sql条件” –lock-all-tables > 路径
	
	1
	mysqldump -hhostname -uusername -p dbname tbname>xxxx.sql
	** 按指定条件导出数据库表内容。(-w选项 –where）
	
	1
	mysqldump -hhostname -uusername-p dbname tbname -w'id >= 1 and id<= 10000'--skip-lock-tables > xxxx.sql
	或
	
	1
	mysqldump -hhostname -uusername -p dbname tbname --where='unit_id >= 1 and unit_id <= 10000'> ~/xxxx.sql
	mysqldump导出库表详细举例
	
	1. 导出整个数据库
	
	mysqldump -u 用户名 -p数据库名 > 导出的文件名
	
	1
	>mysqldump -u breezelark-p mydb > mydb.sql
	2. 导出一个表（包括数据结构及数据）
	
	mysqldump -u 用户名 -p数据库名 表名> 导出的文件名
	
	1
	mysqldump -u lingxi -p mydb mytb> mytb.sql
	3. 导出一个数据库结构（无数据只有结构）
	
	1
	mysqldump -u lingxi -p -d --add-drop-table mydb >mydb.sql
	-d 没有数据–add-drop-table 在每个create语句之前增加一个drop table
	
	当然大家可以mysqldump –help查看帮助了解更多更详细的参数说明呵呵！
